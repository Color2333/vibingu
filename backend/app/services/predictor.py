"""é¢„æµ‹ & å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ¬¡æ—¥ Vibe é¢„æµ‹ - åŸºäºå†å²æ¨¡å¼é¢„æµ‹æ˜å¤©çš„çŠ¶æ€
2. å¼‚å¸¸æ¨¡å¼æ£€æµ‹ - è¯†åˆ«åç¦»æ­£å¸¸æ¨¡å¼çš„è¡Œä¸º
3. å› æœå½’å› åˆ†æ - åˆ†æå½±å“çŠ¶æ€çš„å…³é”®å› ç´ 
4. What-if æ¨¡æ‹Ÿ - æ¨¡æ‹Ÿä¸åŒè¡Œä¸ºçš„å½±å“

å¢å¼ºç‰ˆ v0.2:
- AI é©±åŠ¨çš„é¢„æµ‹åˆ†æ
- æ›´ç²¾å‡†çš„å¼‚å¸¸æ£€æµ‹
- ä¸ªæ€§åŒ–å¥åº·å»ºè®®
- æ™ºèƒ½é£é™©è¯„ä¼°
"""
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta, date
from collections import defaultdict
import statistics
import json
from sqlalchemy.orm import Session
from sqlalchemy import and_

from app.database import SessionLocal
from app.models import LifeStream, DailySummary

logger = logging.getLogger(__name__)


class Predictor:
    """é¢„æµ‹ä¸å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.db: Session = SessionLocal()
    
    def __del__(self):
        if hasattr(self, 'db'):
            self.db.close()
    
    def predict_tomorrow_vibe(self) -> Dict[str, Any]:
        """
        é¢„æµ‹æ˜å¤©çš„ Vibe Score
        
        åŸºäº:
        - åŒæ˜ŸæœŸå‡ çš„å†å²è¡¨ç°
        - æœ€è¿‘7å¤©è¶‹åŠ¿
        - ä»Šæ—¥æ´»åŠ¨å½±å“
        """
        today = datetime.now().date()
        tomorrow = today + timedelta(days=1)
        tomorrow_weekday = tomorrow.weekday()
        
        # è·å–å†å²åŒæ˜ŸæœŸå‡ æ•°æ®
        historical_scores = self._get_historical_weekday_scores(tomorrow_weekday, weeks=8)
        
        # è·å–æœ€è¿‘7å¤©è¶‹åŠ¿
        recent_trend = self._get_recent_trend(7)
        
        # è·å–ä»Šæ—¥å› ç´ 
        today_factors = self._analyze_today_factors()
        
        # è®¡ç®—é¢„æµ‹åˆ†æ•°
        base_score = 50  # é»˜è®¤åŸºå‡†
        
        if historical_scores:
            base_score = statistics.mean(historical_scores)
        
        # è¶‹åŠ¿è°ƒæ•´
        trend_adjustment = 0
        if recent_trend["direction"] == "up":
            trend_adjustment = min(recent_trend["strength"] * 2, 10)
        elif recent_trend["direction"] == "down":
            trend_adjustment = -min(recent_trend["strength"] * 2, 10)
        
        # ä»Šæ—¥å› ç´ è°ƒæ•´
        factor_adjustment = self._calculate_factor_adjustment(today_factors)
        
        predicted_score = base_score + trend_adjustment + factor_adjustment
        predicted_score = max(0, min(100, predicted_score))
        
        # ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(len(historical_scores), recent_trend)
        
        return {
            "predicted_date": tomorrow.isoformat(),
            "predicted_score": round(predicted_score, 1),
            "confidence": confidence,
            "base_score": round(base_score, 1),
            "adjustments": {
                "trend": round(trend_adjustment, 1),
                "today_factors": round(factor_adjustment, 1)
            },
            "factors": today_factors,
            "historical_reference": {
                "weekday": self._weekday_name(tomorrow_weekday),
                "avg_score": round(base_score, 1),
                "sample_size": len(historical_scores)
            },
            "recent_trend": recent_trend
        }
    
    def detect_anomalies(self, days: int = 30) -> Dict[str, Any]:
        """
        æ£€æµ‹å¼‚å¸¸æ¨¡å¼
        
        è¯†åˆ«:
        - çªç„¶çš„åˆ†æ•°æ³¢åŠ¨
        - å¼‚å¸¸çš„æ—¶é—´æ¨¡å¼
        - åç¦»å¸¸è§„çš„è¡Œä¸º
        """
        start_date = datetime.now() - timedelta(days=days)
        
        records = self.db.query(LifeStream).filter(
            LifeStream.created_at >= start_date
        ).order_by(LifeStream.created_at).all()
        
        if len(records) < 7:
            return {"anomalies": [], "message": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå¼‚å¸¸æ£€æµ‹"}
        
        anomalies = []
        
        # 1. æ£€æµ‹åˆ†æ•°å¼‚å¸¸
        score_anomalies = self._detect_score_anomalies(records)
        anomalies.extend(score_anomalies)
        
        # 2. æ£€æµ‹æ—¶é—´æ¨¡å¼å¼‚å¸¸
        time_anomalies = self._detect_time_anomalies(records)
        anomalies.extend(time_anomalies)
        
        # 3. æ£€æµ‹æ´»åŠ¨é¢‘ç‡å¼‚å¸¸
        frequency_anomalies = self._detect_frequency_anomalies(records)
        anomalies.extend(frequency_anomalies)
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        anomalies.sort(key=lambda x: x.get("severity", 0), reverse=True)
        
        return {
            "period_days": days,
            "total_records": len(records),
            "anomaly_count": len(anomalies),
            "anomalies": anomalies[:10]  # è¿”å›å‰10ä¸ª
        }
    
    def analyze_causation(self, target_date: Optional[date] = None) -> Dict[str, Any]:
        """
        å› æœå½’å› åˆ†æ
        
        åˆ†æå½±å“å½“æ—¥çŠ¶æ€çš„å…³é”®å› ç´ 
        """
        if target_date is None:
            target_date = datetime.now().date()
        
        # è·å–ç›®æ ‡æ—¥æœŸçš„æ•°æ®
        start_time = datetime.combine(target_date, datetime.min.time())
        end_time = datetime.combine(target_date + timedelta(days=1), datetime.min.time())
        
        records = self.db.query(LifeStream).filter(
            and_(
                LifeStream.created_at >= start_time,
                LifeStream.created_at < end_time
            )
        ).all()
        
        # è·å–å‰ä¸€å¤©çš„æ•°æ®ç”¨äºå¯¹æ¯”
        prev_start = start_time - timedelta(days=1)
        prev_end = start_time
        
        prev_records = self.db.query(LifeStream).filter(
            and_(
                LifeStream.created_at >= prev_start,
                LifeStream.created_at < prev_end
            )
        ).all()
        
        # åˆ†æå„å› ç´ çš„å½±å“
        factors = []
        
        # ç¡çœ å› ç´ 
        sleep_impact = self._analyze_sleep_impact(records, prev_records)
        if sleep_impact:
            factors.append(sleep_impact)
        
        # é¥®é£Ÿå› ç´ 
        diet_impact = self._analyze_diet_impact(records)
        if diet_impact:
            factors.append(diet_impact)
        
        # è¿åŠ¨å› ç´ 
        activity_impact = self._analyze_activity_impact(records)
        if activity_impact:
            factors.append(activity_impact)
        
        # ç¤¾äº¤å› ç´ 
        social_impact = self._analyze_social_impact(records)
        if social_impact:
            factors.append(social_impact)
        
        # å±å¹•æ—¶é—´å› ç´ 
        screen_impact = self._analyze_screen_impact(records)
        if screen_impact:
            factors.append(screen_impact)
        
        # æŒ‰å½±å“åŠ›æ’åº
        factors.sort(key=lambda x: abs(x.get("impact_score", 0)), reverse=True)
        
        # è®¡ç®—æ€»ä½“è¯„ä»·
        total_positive = sum(f["impact_score"] for f in factors if f["impact_score"] > 0)
        total_negative = sum(f["impact_score"] for f in factors if f["impact_score"] < 0)
        
        return {
            "date": target_date.isoformat(),
            "record_count": len(records),
            "factors": factors,
            "summary": {
                "positive_impact": round(total_positive, 1),
                "negative_impact": round(total_negative, 1),
                "net_impact": round(total_positive + total_negative, 1)
            },
            "top_positive": factors[0] if factors and factors[0]["impact_score"] > 0 else None,
            "top_negative": next((f for f in factors if f["impact_score"] < 0), None)
        }
    
    def what_if_simulation(self, scenario: Dict[str, Any]) -> Dict[str, Any]:
        """
        What-if æ¨¡æ‹Ÿ
        
        æ¨¡æ‹Ÿä¸åŒè¡Œä¸ºé€‰æ‹©çš„å½±å“
        
        scenario ç¤ºä¾‹:
        {
            "sleep_hours": 8,
            "exercise_minutes": 30,
            "caffeine_after_2pm": False,
            "screen_hours": 4
        }
        """
        base_score = 50
        adjustments = []
        
        # ç¡çœ å½±å“
        sleep_hours = scenario.get("sleep_hours")
        if sleep_hours is not None:
            if 7 <= sleep_hours <= 9:
                adj = 10
                adjustments.append({"factor": "ç¡çœ ", "impact": adj, "reason": "ç†æƒ³ç¡çœ æ—¶é•¿"})
            elif sleep_hours < 6:
                adj = -15
                adjustments.append({"factor": "ç¡çœ ", "impact": adj, "reason": "ç¡çœ ä¸è¶³"})
            elif sleep_hours > 9:
                adj = -5
                adjustments.append({"factor": "ç¡çœ ", "impact": adj, "reason": "ç¡çœ è¿‡å¤š"})
            else:
                adj = 5
                adjustments.append({"factor": "ç¡çœ ", "impact": adj, "reason": "ç¡çœ åŸºæœ¬å……è¶³"})
            base_score += adj
        
        # è¿åŠ¨å½±å“
        exercise_minutes = scenario.get("exercise_minutes")
        if exercise_minutes is not None:
            if exercise_minutes >= 30:
                adj = 12
                adjustments.append({"factor": "è¿åŠ¨", "impact": adj, "reason": "å……è¶³è¿åŠ¨"})
            elif exercise_minutes > 0:
                adj = 5
                adjustments.append({"factor": "è¿åŠ¨", "impact": adj, "reason": "æœ‰è¿åŠ¨"})
            else:
                adj = -5
                adjustments.append({"factor": "è¿åŠ¨", "impact": adj, "reason": "ç¼ºä¹è¿åŠ¨"})
            base_score += adj
        
        # å’–å•¡å› å½±å“
        caffeine_after_2pm = scenario.get("caffeine_after_2pm")
        if caffeine_after_2pm is not None:
            if caffeine_after_2pm:
                adj = -8
                adjustments.append({"factor": "å’–å•¡å› ", "impact": adj, "reason": "ä¸‹åˆæ‘„å…¥å’–å•¡å› å¯èƒ½å½±å“ç¡çœ "})
            else:
                adj = 3
                adjustments.append({"factor": "å’–å•¡å› ", "impact": adj, "reason": "é¿å…ä¸‹åˆå’–å•¡å› "})
            base_score += adj
        
        # å±å¹•æ—¶é—´å½±å“
        screen_hours = scenario.get("screen_hours")
        if screen_hours is not None:
            if screen_hours <= 4:
                adj = 8
                adjustments.append({"factor": "å±å¹•æ—¶é—´", "impact": adj, "reason": "å¥åº·å±å¹•æ—¶é—´"})
            elif screen_hours <= 6:
                adj = 0
                adjustments.append({"factor": "å±å¹•æ—¶é—´", "impact": adj, "reason": "ä¸­ç­‰å±å¹•æ—¶é—´"})
            else:
                adj = -10
                adjustments.append({"factor": "å±å¹•æ—¶é—´", "impact": adj, "reason": "è¿‡å¤šå±å¹•æ—¶é—´"})
            base_score += adj
        
        predicted_score = max(0, min(100, base_score))
        
        return {
            "scenario": scenario,
            "predicted_score": round(predicted_score, 1),
            "adjustments": adjustments,
            "recommendations": self._generate_recommendations(adjustments)
        }
    
    def get_health_alerts(self) -> List[Dict[str, Any]]:
        """
        è·å–å¥åº·æé†’
        
        åŸºäºè¿‘æœŸæ•°æ®ç”Ÿæˆä¸ªæ€§åŒ–æé†’
        """
        alerts = []
        
        # æ£€æŸ¥æœ€è¿‘çš„ç¡çœ æ¨¡å¼
        sleep_alert = self._check_sleep_pattern()
        if sleep_alert:
            alerts.append(sleep_alert)
        
        # æ£€æŸ¥è¿åŠ¨é¢‘ç‡
        activity_alert = self._check_activity_pattern()
        if activity_alert:
            alerts.append(activity_alert)
        
        # æ£€æŸ¥å±å¹•æ—¶é—´è¶‹åŠ¿
        screen_alert = self._check_screen_pattern()
        if screen_alert:
            alerts.append(screen_alert)
        
        # æ£€æŸ¥æƒ…ç»ªè¶‹åŠ¿
        mood_alert = self._check_mood_pattern()
        if mood_alert:
            alerts.append(mood_alert)
        
        return alerts
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _get_historical_weekday_scores(self, weekday: int, weeks: int) -> List[float]:
        """è·å–å†å²åŒæ˜ŸæœŸå‡ çš„åˆ†æ•°"""
        scores = []
        
        for i in range(1, weeks + 1):
            target_date = datetime.now().date() - timedelta(weeks=i)
            # è°ƒæ•´åˆ°ç›®æ ‡æ˜ŸæœŸå‡ 
            days_diff = (target_date.weekday() - weekday) % 7
            target_date = target_date - timedelta(days=days_diff)
            
            # æŸ¥è¯¢è¯¥æ—¥æœŸçš„è®°å½•
            start_time = datetime.combine(target_date, datetime.min.time())
            end_time = datetime.combine(target_date + timedelta(days=1), datetime.min.time())
            
            records = self.db.query(LifeStream).filter(
                and_(
                    LifeStream.created_at >= start_time,
                    LifeStream.created_at < end_time
                )
            ).all()
            
            if records:
                day_scores = []
                for r in records:
                    if r.dimension_scores:
                        avg = sum(r.dimension_scores.values()) / len(r.dimension_scores)
                        day_scores.append(avg)
                
                if day_scores:
                    scores.append(statistics.mean(day_scores))
        
        return scores
    
    def _get_recent_trend(self, days: int) -> Dict[str, Any]:
        """è·å–æœ€è¿‘çš„è¶‹åŠ¿"""
        start_date = datetime.now() - timedelta(days=days)
        
        records = self.db.query(LifeStream).filter(
            LifeStream.created_at >= start_date
        ).order_by(LifeStream.created_at).all()
        
        if len(records) < 3:
            return {"direction": "stable", "strength": 0}
        
        # æŒ‰å¤©è®¡ç®—å¹³å‡åˆ†
        daily_scores: Dict[str, List[float]] = defaultdict(list)
        
        for r in records:
            if r.created_at and r.dimension_scores:
                date_key = r.created_at.strftime("%Y-%m-%d")
                avg = sum(r.dimension_scores.values()) / len(r.dimension_scores)
                daily_scores[date_key].append(avg)
        
        if len(daily_scores) < 2:
            return {"direction": "stable", "strength": 0}
        
        # è®¡ç®—è¶‹åŠ¿
        sorted_days = sorted(daily_scores.keys())
        first_half = sorted_days[:len(sorted_days)//2]
        second_half = sorted_days[len(sorted_days)//2:]
        
        first_avg = statistics.mean([
            statistics.mean(daily_scores[d]) for d in first_half if daily_scores[d]
        ]) if first_half else 50
        
        second_avg = statistics.mean([
            statistics.mean(daily_scores[d]) for d in second_half if daily_scores[d]
        ]) if second_half else 50
        
        diff = second_avg - first_avg
        
        if diff > 3:
            return {"direction": "up", "strength": min(abs(diff), 15)}
        elif diff < -3:
            return {"direction": "down", "strength": min(abs(diff), 15)}
        else:
            return {"direction": "stable", "strength": 0}
    
    def _analyze_today_factors(self) -> List[Dict[str, Any]]:
        """åˆ†æä»Šæ—¥å› ç´ """
        today = datetime.now().date()
        start_time = datetime.combine(today, datetime.min.time())
        end_time = datetime.now()
        
        records = self.db.query(LifeStream).filter(
            and_(
                LifeStream.created_at >= start_time,
                LifeStream.created_at < end_time
            )
        ).all()
        
        factors = []
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_counts: Dict[str, int] = defaultdict(int)
        for r in records:
            if r.category:
                category_counts[r.category] += 1
        
        # æ£€æŸ¥ç¡çœ è®°å½•
        if category_counts.get("SLEEP", 0) > 0:
            factors.append({"type": "sleep", "status": "recorded", "impact": "positive"})
        
        # æ£€æŸ¥è¿åŠ¨è®°å½•
        if category_counts.get("ACTIVITY", 0) > 0:
            factors.append({"type": "exercise", "status": "active", "impact": "positive"})
        
        # æ£€æŸ¥é¥®é£Ÿä¸­çš„å’–å•¡å› 
        for r in records:
            if r.category == "DIET" and r.meta_data:
                caffeine = r.meta_data.get("caffeine_mg", 0)
                if caffeine and r.created_at.hour >= 14:
                    factors.append({"type": "caffeine", "status": "late_intake", "impact": "negative"})
                    break
        
        return factors
    
    def _calculate_factor_adjustment(self, factors: List[Dict]) -> float:
        """è®¡ç®—å› ç´ è°ƒæ•´å€¼"""
        adjustment = 0
        
        for f in factors:
            if f.get("impact") == "positive":
                adjustment += 3
            elif f.get("impact") == "negative":
                adjustment -= 5
        
        return adjustment
    
    def _calculate_confidence(self, sample_size: int, trend: Dict) -> str:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if sample_size >= 6 and trend["strength"] < 5:
            return "high"
        elif sample_size >= 3:
            return "medium"
        else:
            return "low"
    
    def _weekday_name(self, weekday: int) -> str:
        """è·å–æ˜ŸæœŸå‡ åç§°"""
        names = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"]
        return names[weekday]
    
    def _detect_score_anomalies(self, records: List[LifeStream]) -> List[Dict]:
        """æ£€æµ‹åˆ†æ•°å¼‚å¸¸"""
        anomalies = []
        
        # æŒ‰å¤©è®¡ç®—åˆ†æ•°
        daily_scores: Dict[str, List[float]] = defaultdict(list)
        
        for r in records:
            if r.created_at and r.dimension_scores:
                date_key = r.created_at.strftime("%Y-%m-%d")
                avg = sum(r.dimension_scores.values()) / len(r.dimension_scores)
                daily_scores[date_key].append(avg)
        
        if len(daily_scores) < 3:
            return anomalies
        
        # è®¡ç®—ç»Ÿè®¡å€¼
        all_daily_avgs = [statistics.mean(scores) for scores in daily_scores.values() if scores]
        
        if len(all_daily_avgs) < 3:
            return anomalies
        
        mean_score = statistics.mean(all_daily_avgs)
        std_score = statistics.stdev(all_daily_avgs) if len(all_daily_avgs) > 1 else 10
        
        # æ£€æµ‹å¼‚å¸¸
        for date_str, scores in daily_scores.items():
            day_avg = statistics.mean(scores)
            z_score = (day_avg - mean_score) / std_score if std_score > 0 else 0
            
            if abs(z_score) > 2:
                anomalies.append({
                    "type": "score_deviation",
                    "date": date_str,
                    "value": round(day_avg, 1),
                    "expected": round(mean_score, 1),
                    "deviation": round(z_score, 2),
                    "severity": min(abs(z_score), 3),
                    "description": f"{'å¼‚å¸¸é«˜åˆ†' if z_score > 0 else 'å¼‚å¸¸ä½åˆ†'}: {round(day_avg, 1)} (å¹³å‡ {round(mean_score, 1)})"
                })
        
        return anomalies
    
    def _detect_time_anomalies(self, records: List[LifeStream]) -> List[Dict]:
        """æ£€æµ‹æ—¶é—´æ¨¡å¼å¼‚å¸¸"""
        anomalies = []
        
        # ç»Ÿè®¡æ¯å°æ—¶çš„æ´»åŠ¨
        hourly_counts: Dict[int, int] = defaultdict(int)
        
        for r in records:
            if r.created_at:
                hourly_counts[r.created_at.hour] += 1
        
        # æ£€æµ‹æ·±å¤œæ´»åŠ¨
        late_night_count = sum(hourly_counts.get(h, 0) for h in [0, 1, 2, 3, 4])
        total_count = sum(hourly_counts.values())
        
        if total_count > 0 and late_night_count / total_count > 0.15:
            anomalies.append({
                "type": "late_night_activity",
                "value": late_night_count,
                "percentage": round(late_night_count / total_count * 100, 1),
                "severity": 2,
                "description": f"æ·±å¤œæ´»åŠ¨åå¤š ({round(late_night_count / total_count * 100, 1)}%)"
            })
        
        return anomalies
    
    def _detect_frequency_anomalies(self, records: List[LifeStream]) -> List[Dict]:
        """æ£€æµ‹æ´»åŠ¨é¢‘ç‡å¼‚å¸¸"""
        anomalies = []
        
        # æŒ‰å¤©ç»Ÿè®¡æ´»åŠ¨æ•°é‡
        daily_counts: Dict[str, int] = defaultdict(int)
        
        for r in records:
            if r.created_at:
                date_key = r.created_at.strftime("%Y-%m-%d")
                daily_counts[date_key] += 1
        
        if len(daily_counts) < 3:
            return anomalies
        
        counts = list(daily_counts.values())
        mean_count = statistics.mean(counts)
        std_count = statistics.stdev(counts) if len(counts) > 1 else mean_count / 2
        
        # æ£€æµ‹è®°å½•è¿‡å°‘çš„æ—¥å­
        for date_str, count in daily_counts.items():
            if count < mean_count - 2 * std_count and count < mean_count * 0.3:
                anomalies.append({
                    "type": "low_activity",
                    "date": date_str,
                    "value": count,
                    "expected": round(mean_count, 1),
                    "severity": 1,
                    "description": f"æ´»åŠ¨è®°å½•åå°‘: {count}æ¡ (å¹³å‡ {round(mean_count, 1)}æ¡)"
                })
        
        return anomalies
    
    def _analyze_sleep_impact(self, records, prev_records) -> Optional[Dict]:
        """åˆ†æç¡çœ å¯¹å½“æ—¥çš„å½±å“"""
        sleep_records = [r for r in prev_records if r.category == "SLEEP"]
        
        if not sleep_records:
            return None
        
        # ç®€åŒ–åˆ†æ
        return {
            "factor": "ç¡çœ ",
            "impact_score": 5 if sleep_records else -5,
            "description": f"å‰ä¸€å¤©æœ‰ {len(sleep_records)} æ¡ç¡çœ è®°å½•",
            "recommendation": "ä¿æŒè§„å¾‹ç¡çœ "
        }
    
    def _analyze_diet_impact(self, records) -> Optional[Dict]:
        """åˆ†æé¥®é£Ÿå½±å“"""
        diet_records = [r for r in records if r.category == "DIET"]
        
        if not diet_records:
            return None
        
        return {
            "factor": "é¥®é£Ÿ",
            "impact_score": 3,
            "description": f"ä»Šæ—¥ {len(diet_records)} æ¡é¥®é£Ÿè®°å½•",
            "recommendation": "æ³¨æ„è¥å…»å‡è¡¡"
        }
    
    def _analyze_activity_impact(self, records) -> Optional[Dict]:
        """åˆ†æè¿åŠ¨å½±å“"""
        activity_records = [r for r in records if r.category == "ACTIVITY"]
        
        if activity_records:
            return {
                "factor": "è¿åŠ¨",
                "impact_score": 8,
                "description": f"ä»Šæ—¥ {len(activity_records)} æ¡è¿åŠ¨è®°å½•",
                "recommendation": "ç»§ç»­ä¿æŒè¿åŠ¨ä¹ æƒ¯"
            }
        else:
            return {
                "factor": "è¿åŠ¨",
                "impact_score": -3,
                "description": "ä»Šæ—¥æš‚æ— è¿åŠ¨è®°å½•",
                "recommendation": "å»ºè®®å¢åŠ é€‚é‡è¿åŠ¨"
            }
    
    def _analyze_social_impact(self, records) -> Optional[Dict]:
        """åˆ†æç¤¾äº¤å½±å“"""
        social_records = [r for r in records if r.category == "SOCIAL"]
        
        if social_records:
            return {
                "factor": "ç¤¾äº¤",
                "impact_score": 5,
                "description": f"ä»Šæ—¥ {len(social_records)} æ¡ç¤¾äº¤è®°å½•",
                "recommendation": "ç¤¾äº¤äº’åŠ¨æœ‰åŠ©å¿ƒç†å¥åº·"
            }
        
        return None
    
    def _analyze_screen_impact(self, records) -> Optional[Dict]:
        """åˆ†æå±å¹•æ—¶é—´å½±å“"""
        screen_records = [r for r in records if r.category == "SCREEN"]
        
        if screen_records:
            total_hours = 0
            for r in screen_records:
                if r.meta_data:
                    total_hours += r.meta_data.get("screen_hours", 0)
            
            if total_hours > 6:
                return {
                    "factor": "å±å¹•æ—¶é—´",
                    "impact_score": -8,
                    "description": f"ä»Šæ—¥å±å¹•æ—¶é—´çº¦ {total_hours:.1f} å°æ—¶ï¼Œåå¤š",
                    "recommendation": "é€‚å½“å‡å°‘å±å¹•æ—¶é—´"
                }
            elif total_hours > 0:
                return {
                    "factor": "å±å¹•æ—¶é—´",
                    "impact_score": 0,
                    "description": f"ä»Šæ—¥å±å¹•æ—¶é—´çº¦ {total_hours:.1f} å°æ—¶",
                    "recommendation": "ä¿æŒåˆç†å±å¹•æ—¶é—´"
                }
        
        return None
    
    def _generate_recommendations(self, adjustments: List[Dict]) -> List[str]:
        """åŸºäºè°ƒæ•´ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        for adj in adjustments:
            if adj["impact"] < 0:
                if adj["factor"] == "ç¡çœ ":
                    recommendations.append("å°è¯•å¢åŠ ç¡çœ æ—¶é—´åˆ°7-9å°æ—¶")
                elif adj["factor"] == "å’–å•¡å› ":
                    recommendations.append("é¿å…ä¸‹åˆ2ç‚¹åæ‘„å…¥å’–å•¡å› ")
                elif adj["factor"] == "å±å¹•æ—¶é—´":
                    recommendations.append("è®¾å®šå±å¹•æ—¶é—´é™åˆ¶ï¼Œæ¯å°æ—¶ä¼‘æ¯5åˆ†é’Ÿ")
                elif adj["factor"] == "è¿åŠ¨":
                    recommendations.append("æ¯å¤©è‡³å°‘è¿›è¡Œ30åˆ†é’Ÿä¸­ç­‰å¼ºåº¦è¿åŠ¨")
        
        return recommendations
    
    def _check_sleep_pattern(self) -> Optional[Dict]:
        """æ£€æŸ¥ç¡çœ æ¨¡å¼"""
        # è·å–æœ€è¿‘7å¤©çš„ç¡çœ è®°å½•
        start_date = datetime.now() - timedelta(days=7)
        
        sleep_records = self.db.query(LifeStream).filter(
            and_(
                LifeStream.created_at >= start_date,
                LifeStream.category == "SLEEP"
            )
        ).all()
        
        if len(sleep_records) < 3:
            return {
                "type": "sleep",
                "level": "info",
                "icon": "ğŸ˜´",
                "title": "ç¡çœ è®°å½•ä¸è¶³",
                "message": "æœ€è¿‘7å¤©åªæœ‰ {} æ¡ç¡çœ è®°å½•ï¼Œå»ºè®®æ¯å¤©è®°å½•ç¡çœ æƒ…å†µ".format(len(sleep_records)),
                "suggestion": "å…»æˆæ¯å¤©è®°å½•ç¡çœ çš„ä¹ æƒ¯ï¼Œæœ‰åŠ©äºäº†è§£ä½œæ¯è§„å¾‹"
            }
        
        # æ£€æŸ¥ç¡çœ æ—¶é—´æ˜¯å¦è§„å¾‹ï¼ˆè®°å½•æ—¶é—´çš„æ ‡å‡†å·®ï¼‰
        sleep_hours = []
        for r in sleep_records:
            if r.created_at:
                sleep_hours.append(r.created_at.hour)
        
        if sleep_hours and len(sleep_hours) >= 3:
            avg_hour = sum(sleep_hours) / len(sleep_hours)
            variance = sum((h - avg_hour) ** 2 for h in sleep_hours) / len(sleep_hours)
            std_dev = variance ** 0.5
            
            if std_dev > 3:
                return {
                    "type": "sleep",
                    "level": "warning",
                    "icon": "â°",
                    "title": "ä½œæ¯ä¸è§„å¾‹",
                    "message": "ç¡çœ æ—¶é—´æ³¢åŠ¨è¾ƒå¤§ï¼ˆæ ‡å‡†å·® {:.1f} å°æ—¶ï¼‰ï¼Œå»ºè®®å›ºå®šä½œæ¯".format(std_dev),
                    "suggestion": "å°è¯•æ¯å¤©åœ¨ç›¸åŒæ—¶é—´å…¥ç¡ï¼Œæœ‰åŠ©äºæé«˜ç¡çœ è´¨é‡"
                }
            
            # æ£€æŸ¥æ˜¯å¦ç¡å¾—å¤ªæ™š
            late_count = sum(1 for h in sleep_hours if h >= 1 and h <= 6)
            if late_count >= 3:
                return {
                    "type": "sleep",
                    "level": "warning",
                    "icon": "ğŸŒ™",
                    "title": "ç†¬å¤œè¾ƒå¤š",
                    "message": "æœ€è¿‘7å¤©æœ‰ {} æ¬¡å‡Œæ™¨åæ‰ç¡è§‰".format(late_count),
                    "suggestion": "å°½é‡åœ¨23ç‚¹å‰å…¥ç¡ï¼Œä¿è¯å……è¶³ç¡çœ "
                }
        
        return None
    
    def _check_activity_pattern(self) -> Optional[Dict]:
        """æ£€æŸ¥è¿åŠ¨æ¨¡å¼"""
        start_date = datetime.now() - timedelta(days=7)
        
        activity_records = self.db.query(LifeStream).filter(
            and_(
                LifeStream.created_at >= start_date,
                LifeStream.category == "ACTIVITY"
            )
        ).all()
        
        activity_count = len(activity_records)
        
        if activity_count == 0:
            return {
                "type": "activity",
                "level": "warning",
                "icon": "ğŸƒ",
                "title": "ç¼ºä¹è¿åŠ¨",
                "message": "æœ€è¿‘7å¤©æ²¡æœ‰è¿åŠ¨è®°å½•",
                "suggestion": "æ¯å¤©30åˆ†é’Ÿä¸­ç­‰å¼ºåº¦è¿åŠ¨å¯ä»¥æ˜¾è‘—æå‡èº«å¿ƒçŠ¶æ€"
            }
        elif activity_count < 3:
            return {
                "type": "activity",
                "level": "info",
                "icon": "ğŸ’ª",
                "title": "è¿åŠ¨å¯ä»¥æ›´å¤š",
                "message": "æœ€è¿‘7å¤©åªæœ‰ {} æ¬¡è¿åŠ¨è®°å½•".format(activity_count),
                "suggestion": "å»ºè®®æ¯å‘¨è‡³å°‘è¿åŠ¨3-5æ¬¡ï¼Œæ¯æ¬¡30åˆ†é’Ÿä»¥ä¸Š"
            }
        
        return None
    
    def _check_screen_pattern(self) -> Optional[Dict]:
        """æ£€æŸ¥å±å¹•æ—¶é—´æ¨¡å¼"""
        start_date = datetime.now() - timedelta(days=7)
        
        screen_records = self.db.query(LifeStream).filter(
            and_(
                LifeStream.created_at >= start_date,
                LifeStream.category == "SCREEN"
            )
        ).all()
        
        if not screen_records:
            return None
        
        # ç»Ÿè®¡æ€»å±å¹•æ—¶é—´
        total_hours = 0
        days_with_data = set()
        
        for r in screen_records:
            if r.meta_data and r.meta_data.get("screen_hours"):
                total_hours += r.meta_data.get("screen_hours", 0)
            if r.created_at:
                days_with_data.add(r.created_at.date())
        
        if days_with_data:
            avg_daily = total_hours / len(days_with_data)
            
            if avg_daily > 8:
                return {
                    "type": "screen",
                    "level": "warning",
                    "icon": "ğŸ“±",
                    "title": "å±å¹•æ—¶é—´è¿‡é•¿",
                    "message": "æ—¥å‡å±å¹•æ—¶é—´çº¦ {:.1f} å°æ—¶ï¼Œå»ºè®®æ§åˆ¶åœ¨6å°æ—¶ä»¥å†…".format(avg_daily),
                    "suggestion": "è®¾ç½®å±å¹•æ—¶é—´é™åˆ¶ï¼Œæ¯ä½¿ç”¨1å°æ—¶ä¼‘æ¯5-10åˆ†é’Ÿ"
                }
            elif avg_daily > 6:
                return {
                    "type": "screen",
                    "level": "info",
                    "icon": "ğŸ‘€",
                    "title": "æ³¨æ„å±å¹•æ—¶é—´",
                    "message": "æ—¥å‡å±å¹•æ—¶é—´çº¦ {:.1f} å°æ—¶".format(avg_daily),
                    "suggestion": "é€‚å½“å‡å°‘éå¿…è¦çš„å±å¹•ä½¿ç”¨ï¼Œå¤šè¿›è¡Œæˆ·å¤–æ´»åŠ¨"
                }
        
        # æ£€æŸ¥æ·±å¤œä½¿ç”¨å±å¹•
        late_screen = sum(1 for r in screen_records if r.created_at and r.created_at.hour >= 23)
        if late_screen >= 3:
            return {
                "type": "screen",
                "level": "warning",
                "icon": "ğŸŒƒ",
                "title": "ç¡å‰å±å¹•ä½¿ç”¨",
                "message": "æœ€è¿‘æœ‰ {} æ¬¡æ·±å¤œä½¿ç”¨å±å¹•çš„è®°å½•".format(late_screen),
                "suggestion": "ç¡å‰1å°æ—¶é¿å…ä½¿ç”¨ç”µå­è®¾å¤‡ï¼Œæœ‰åŠ©äºæ”¹å–„ç¡çœ è´¨é‡"
            }
        
        return None
    
    def _check_mood_pattern(self) -> Optional[Dict]:
        """æ£€æŸ¥æƒ…ç»ªæ¨¡å¼"""
        start_date = datetime.now() - timedelta(days=7)
        
        mood_records = self.db.query(LifeStream).filter(
            and_(
                LifeStream.created_at >= start_date,
                LifeStream.category == "MOOD"
            )
        ).all()
        
        if len(mood_records) < 3:
            return {
                "type": "mood",
                "level": "info",
                "icon": "ğŸ˜Š",
                "title": "è®°å½•ä½ çš„å¿ƒæƒ…",
                "message": "æœ€è¿‘å¿ƒæƒ…è®°å½•è¾ƒå°‘",
                "suggestion": "å®šæœŸè®°å½•å¿ƒæƒ…æœ‰åŠ©äºæƒ…ç»ªè§‰å¯Ÿå’Œç®¡ç†"
            }
        
        # åˆ†æå¿ƒæƒ…æ ‡ç­¾
        negative_keywords = ["ç„¦è™‘", "ç´§å¼ ", "æ‹…å¿ƒ", "å‹åŠ›", "çƒ¦èº", "æ²®ä¸§", "éš¾è¿‡", "ç´¯", "ç–²æƒ«", "å¤±çœ ", "ä¸å®‰"]
        positive_keywords = ["å¼€å¿ƒ", "å¿«ä¹", "æ»¡è¶³", "æ”¾æ¾", "å¹³é™", "å……å®", "æ„‰å¿«", "æœŸå¾…"]
        
        negative_count = 0
        positive_count = 0
        
        for r in mood_records:
            content = (r.raw_content or "") + " " + " ".join(r.tags or [])
            
            for kw in negative_keywords:
                if kw in content:
                    negative_count += 1
                    break
            
            for kw in positive_keywords:
                if kw in content:
                    positive_count += 1
                    break
        
        if negative_count >= 4 and negative_count > positive_count:
            return {
                "type": "mood",
                "level": "warning",
                "icon": "ğŸ’­",
                "title": "æƒ…ç»ªéœ€è¦å…³æ³¨",
                "message": "æœ€è¿‘è´Ÿé¢æƒ…ç»ªè®°å½•è¾ƒå¤šï¼ˆ{} æ¡ï¼‰".format(negative_count),
                "suggestion": "å°è¯•è¿åŠ¨ã€å†¥æƒ³æˆ–ä¸æœ‹å‹äº¤æµï¼Œå¿…è¦æ—¶å¯»æ±‚ä¸“ä¸šå¸®åŠ©"
            }
        
        # æ£€æŸ¥æƒ…ç»ªç»´åº¦å¾—åˆ†
        mood_scores = []
        for r in mood_records:
            if r.dimension_scores and "mood" in r.dimension_scores:
                mood_scores.append(r.dimension_scores["mood"])
        
        if mood_scores:
            avg_mood = sum(mood_scores) / len(mood_scores)
            if avg_mood < 40:
                return {
                    "type": "mood",
                    "level": "warning",
                    "icon": "ğŸ«‚",
                    "title": "æƒ…ç»ªçŠ¶æ€åä½",
                    "message": "æœ€è¿‘æƒ…ç»ªç»´åº¦å¹³å‡å¾—åˆ† {:.0f}".format(avg_mood),
                    "suggestion": "å…³æ³¨è‡ªå·±çš„æƒ…ç»ªå¥åº·ï¼Œåšä¸€äº›è®©è‡ªå·±å¼€å¿ƒçš„äº‹æƒ…"
                }
        
        return None
    
    # ========== AI å¢å¼ºåŠŸèƒ½ v0.2 ==========
    
    async def ai_predict_tomorrow(self) -> Dict[str, Any]:
        """
        AI é©±åŠ¨çš„æ¬¡æ—¥é¢„æµ‹
        
        ç»“åˆå†å²æ•°æ®å’Œ AI åˆ†æï¼Œç»™å‡ºæ›´ç²¾å‡†çš„é¢„æµ‹
        """
        from app.services.ai_client import get_ai_client, AIClientError
        
        # è·å–åŸºç¡€é¢„æµ‹
        base_prediction = self.predict_tomorrow_vibe()
        
        # è·å–æœ€è¿‘çš„è®°å½•æ‘˜è¦
        recent_summary = self._get_recent_summary(7)
        
        if not recent_summary["has_data"]:
            return {
                **base_prediction,
                "ai_enhanced": False,
                "message": "æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨åŸºç¡€é¢„æµ‹"
            }
        
        try:
            ai_client = get_ai_client()
            
            prompt = f"""åŸºäºä»¥ä¸‹ç”¨æˆ·æ•°æ®ï¼Œé¢„æµ‹æ˜å¤©çš„çŠ¶æ€å¹¶ç»™å‡ºå»ºè®®ã€‚

åŸºç¡€é¢„æµ‹åˆ†æ•°: {base_prediction['predicted_score']}
è¿‘7å¤©æ•°æ®æ‘˜è¦:
{json.dumps(recent_summary, ensure_ascii=False, indent=2)}

è¯·åˆ†æ:
1. åŸºäºæ•°æ®æ¨¡å¼ï¼Œæ˜å¤©çŠ¶æ€çš„å¯èƒ½èŒƒå›´
2. å½±å“æ˜å¤©çŠ¶æ€çš„å…³é”®å› ç´ 
3. æå‡æ˜å¤©çŠ¶æ€çš„å…·ä½“å»ºè®®

è¿”å›JSONæ ¼å¼:
{{
    "adjusted_score": é¢„æµ‹åˆ†æ•°ï¼ˆä¿æŒåŸåˆ†æ•°æˆ–å¾®è°ƒï¼‰ï¼Œ
    "confidence": "high/medium/low",
    "key_factors": ["å› ç´ 1", "å› ç´ 2"],
    "improvement_tips": ["å»ºè®®1", "å»ºè®®2"],
    "risk_factors": ["é£é™©1"] æˆ– [],
    "morning_suggestion": "æ—©æ™¨çš„ä¸€å¥è¯å»ºè®®"
}}"""
            
            result = await ai_client.chat_completion(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç”Ÿæ´»çŠ¶æ€é¢„æµ‹ä¸“å®¶ã€‚åŸºäºç”¨æˆ·çš„å†å²æ•°æ®æ¨¡å¼è¿›è¡Œé¢„æµ‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=3000,
                task_type="ai_prediction",
                task_description="AI æ¬¡æ—¥é¢„æµ‹",
                json_response=True,
            )
            
            ai_result = result["content"]
            
            if isinstance(ai_result, dict):
                return {
                    **base_prediction,
                    "ai_enhanced": True,
                    "ai_analysis": ai_result,
                    "predicted_score": ai_result.get("adjusted_score", base_prediction["predicted_score"]),
                }
            else:
                raise ValueError("AI è¿”å›æ ¼å¼é”™è¯¯")
                
        except Exception as e:
            logger.error(f"AI é¢„æµ‹é”™è¯¯: {e}")
            return {
                **base_prediction,
                "ai_enhanced": False,
                "error": str(e)
            }
    
    async def ai_detect_risks(self) -> Dict[str, Any]:
        """
        AI é©±åŠ¨çš„é£é™©æ£€æµ‹
        
        åˆ†æè¿‘æœŸæ•°æ®ï¼Œè¯†åˆ«æ½œåœ¨çš„å¥åº·é£é™©
        """
        from app.services.ai_client import get_ai_client, AIClientError
        
        # è·å–å¥åº·æé†’
        alerts = self.get_health_alerts()
        
        # è·å–å¼‚å¸¸æ£€æµ‹
        anomalies = self.detect_anomalies(14)
        
        # è·å–è¿‘æœŸæ•°æ®æ‘˜è¦
        recent_summary = self._get_recent_summary(14)
        
        if not recent_summary["has_data"]:
            return {
                "has_data": False,
                "alerts": alerts,
                "message": "æ•°æ®ä¸è¶³"
            }
        
        try:
            ai_client = get_ai_client()
            
            prompt = f"""åˆ†æä»¥ä¸‹ç”¨æˆ·æ•°æ®ï¼Œè¯†åˆ«æ½œåœ¨çš„å¥åº·é£é™©å’Œéœ€è¦å…³æ³¨çš„æ¨¡å¼ã€‚

ç³»ç»Ÿæ£€æµ‹åˆ°çš„å‘Šè­¦: {json.dumps(alerts, ensure_ascii=False)}
å¼‚å¸¸æ£€æµ‹ç»“æœ: {json.dumps(anomalies.get('anomalies', [])[:5], ensure_ascii=False)}
è¿‘æœŸæ•°æ®æ‘˜è¦: {json.dumps(recent_summary, ensure_ascii=False)}

è¯·åˆ†æ:
1. ç»¼åˆé£é™©è¯„ä¼°
2. éœ€è¦ç«‹å³å…³æ³¨çš„é—®é¢˜
3. é•¿æœŸéœ€è¦æ³¨æ„çš„è¶‹åŠ¿
4. é¢„é˜²å»ºè®®

è¿”å›JSONæ ¼å¼:
{{
    "risk_level": "low/medium/high",
    "risk_score": 0-100,
    "immediate_concerns": ["å…³æ³¨ç‚¹1", "å…³æ³¨ç‚¹2"] æˆ– [],
    "long_term_trends": ["è¶‹åŠ¿1", "è¶‹åŠ¿2"] æˆ– [],
    "preventive_suggestions": ["å»ºè®®1", "å»ºè®®2"],
    "positive_notes": ["ç§¯ææ–¹é¢1", "ç§¯ææ–¹é¢2"]
}}"""
            
            result = await ai_client.chat_completion(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¥åº·é£é™©åˆ†æä¸“å®¶ã€‚æä¾›å®¢è§‚ã€æœ‰å»ºè®¾æ€§çš„åˆ†æï¼Œé¿å…è¿‡åº¦æ‹…å¿§ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=3000,
                task_type="risk_detection",
                task_description="AI é£é™©æ£€æµ‹",
                json_response=True,
            )
            
            ai_result = result["content"]
            
            if isinstance(ai_result, dict):
                return {
                    "has_data": True,
                    "ai_analysis": ai_result,
                    "system_alerts": alerts,
                    "anomaly_count": anomalies.get("anomaly_count", 0)
                }
            else:
                raise ValueError("AI è¿”å›æ ¼å¼é”™è¯¯")
                
        except Exception as e:
            logger.error(f"AI é£é™©æ£€æµ‹é”™è¯¯: {e}")
            return {
                "has_data": True,
                "ai_analysis": None,
                "system_alerts": alerts,
                "error": str(e)
            }
    
    def _get_recent_summary(self, days: int) -> Dict[str, Any]:
        """è·å–è¿‘æœŸæ•°æ®æ‘˜è¦"""
        start_date = datetime.now() - timedelta(days=days)
        
        records = self.db.query(LifeStream).filter(
            LifeStream.created_at >= start_date
        ).all()
        
        if len(records) < 5:
            return {"has_data": False}
        
        # ç»Ÿè®¡å„ç±»åˆ«
        category_counts = defaultdict(int)
        dimension_scores = defaultdict(list)
        
        for r in records:
            if r.category:
                category_counts[r.category] += 1
            if r.dimension_scores:
                for dim, score in r.dimension_scores.items():
                    dimension_scores[dim].append(score)
        
        # è®¡ç®—ç»´åº¦å¹³å‡åˆ†
        dim_avgs = {}
        for dim, scores in dimension_scores.items():
            if scores:
                dim_avgs[dim] = round(sum(scores) / len(scores), 1)
        
        return {
            "has_data": True,
            "period_days": days,
            "total_records": len(records),
            "category_distribution": dict(category_counts),
            "dimension_averages": dim_avgs,
        }


# å…¨å±€å•ä¾‹
_predictor: Optional[Predictor] = None


def get_predictor() -> Predictor:
    """è·å– Predictor å•ä¾‹"""
    global _predictor
    if _predictor is None:
        _predictor = Predictor()
    return _predictor
